#!/usr/bin/env python3
"""
üöÄ –ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π

–ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –Ω–æ–≤–æ–π –º–æ–¥—É–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π:
- –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (crypto_clipped, volume_weighted, vol_regime, market_regime, momentum_enhanced, volume_volatility)
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ (binary classification)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
"""

import argparse
import sys
import os
sys.path.append('.')

from ml_module.systems.regression_system import RegressionSystem
from ml_module.systems.classification_system import ClassificationSystem
from ml_module.utils.config import Config

def train_regression_model(symbol: str, target_type: str = 'crypto_clipped', horizon: int = 10, 
                          timeframes: list = None, n_trials: int = 50):
    """
    –û–±—É—á–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    
    Args:
        symbol: –°–∏–º–≤–æ–ª –º–æ–Ω–µ—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, SOL_USDT)
        target_type: –¢–∏–ø —Ç–∞—Ä–≥–µ—Ç–∞ (crypto_clipped, volume_weighted, vol_regime, market_regime, momentum_enhanced, volume_volatility)
        horizon: –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –±–∞—Ä–∞—Ö
        timeframes: –°–ø–∏—Å–æ–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è multi-timeframe –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        n_trials: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ trials –¥–ª—è Optuna
    """
    print(f"ü§ñ –û–±—É—á–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}")
    print(f"   –¢–∞—Ä–≥–µ—Ç: {target_type}, –ì–æ—Ä–∏–∑–æ–Ω—Ç: {horizon}, –¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {timeframes}")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = Config(
        models_root='models',
        data_root='data',
        log_level='INFO'
    )
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É (–ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º RegressionSystem)
    system = RegressionSystem(config)
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç (–ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º run_experiment)
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")
        metadata = system.run_experiment(
            symbol=symbol,
            target_type=target_type,
            horizon=horizon
        )
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:")
        metrics = metadata.get('metrics', {})
        for metric, value in metrics.items():
            print(f"   {metric.upper()}: {value:.6f}")
        
        baseline = metadata.get('baseline', {})
        if baseline:
            print(f"\nüìà Baseline —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ:")
            if isinstance(baseline, dict):
                for baseline_name, baseline_metrics in baseline.items():
                    if isinstance(baseline_metrics, dict):
                        print(f"   {baseline_name}: RMSE={baseline_metrics.get('rmse', 0):.6f}")
                    else:
                        print(f"   {baseline_name}: {baseline_metrics:.6f}")
            else:
                print(f"   Baseline RMSE: {baseline:.6f}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        print(f"\nüîÆ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É
        try:
            data = system.load_and_validate_data(symbol, ['15m'])
            latest_data = data['15m'].tail(100)
            
            if latest_data is not None and not latest_data.empty:
                prediction_result = system.predict_latest(symbol, latest_data, '15m')
                if prediction_result:
                    print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction_result['prediction']:.6f}")
                    print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {prediction_result['confidence']:.1f}%")
                else:
                    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
            else:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        
        print(f"\nüéâ –û–±—É—á–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return False

def train_classification_model(symbol: str, percent: float = 0.025, horizon: int = 20, n_trials: int = 50):
    """
    –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    
    Args:
        symbol: –°–∏–º–≤–æ–ª –º–æ–Ω–µ—Ç—ã
        percent: –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–æ—Å—Ç–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.025 = 2.5%)
        horizon: –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –±–∞—Ä–∞—Ö
        n_trials: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ trials –¥–ª—è Optuna
    """
    print(f"üîÄ –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}")
    print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–æ—Å—Ç–∞: {percent*100}%, –ì–æ—Ä–∏–∑–æ–Ω—Ç: {horizon}")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = Config(
        models_root='models',
        data_root='data',
        log_level='INFO'
    )
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É
    system = ClassificationSystem(config)
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç (–ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º run_experiment)
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
        metadata = system.run_experiment(
            symbol=symbol,
            percent=percent,
            horizon=horizon
        )
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:")
        metrics = metadata.get('metrics', {})
        for metric, value in metrics.items():
            print(f"   {metric.upper()}: {value:.6f}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–ª–∞—Å—Å–æ–≤
        class_distribution = system.get_class_distribution(symbol)
        if class_distribution:
            print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
            print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ: {class_distribution['original_class_counts']}")
            print(f"   –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: {class_distribution['balanced_class_counts']}")
            print(f"   –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {class_distribution['class_balance_ratio']:.2f}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        print(f"\nüîÆ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É
        try:
            data = system.load_and_validate_data(symbol, ['15m'])
            latest_data = data['15m'].tail(100)
            
            if latest_data is not None and not latest_data.empty:
                prediction_result = system.predict_latest(symbol, latest_data, '15m')
                if prediction_result:
                    print(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction_result['prediction_label']} (–∫–ª–∞—Å—Å {prediction_result['prediction']})")
                    print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {prediction_result['confidence']:.1f}%")
                else:
                    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
            else:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        
        print(f"\nüéâ –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return False

def list_available_models():
    """–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏"""
    import glob
    from pathlib import Path
    
    models_root = Path('models')
    if not models_root.exists():
        print("üìÅ –ü–∞–ø–∫–∞ models –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    print("üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    for model_dir in models_root.glob('*/*'):
        if model_dir.is_dir() and (model_dir / 'meta.json').exists():
            try:
                import json
                with open(model_dir / 'meta.json', 'r') as f:
                    meta = json.load(f)
                
                symbol = meta.get('symbol', model_dir.parent.name)
                task = meta.get('task', model_dir.name)
                saved_at = meta.get('saved_at', meta.get('train_date', 'unknown'))  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º saved_at
                metrics = meta.get('metrics', {})
                model_type = meta.get('model_type', 'unknown')
                features_count = meta.get('features_count', 0)
                
                print(f"   {symbol} ({task}):")
                print(f"     –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")
                print(f"     –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {features_count}")
                print(f"     –î–∞—Ç–∞: {saved_at}")
                
                # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
                if task == 'regression':
                    if 'rmse' in metrics:
                        print(f"     RMSE: {metrics['rmse']:.6f}")
                    if 'mae' in metrics:
                        print(f"     MAE: {metrics['mae']:.6f}")
                    if 'r2' in metrics:
                        print(f"     R¬≤: {metrics['r2']:.4f}")
                elif task == 'classification':
                    if 'accuracy' in metrics:
                        print(f"     Accuracy: {metrics['accuracy']:.4f}")
                    if 'f1_score' in metrics:
                        print(f"     F1: {metrics['f1_score']:.4f}")
                    if 'precision' in metrics:
                        print(f"     Precision: {metrics['precision']:.4f}")
                    if 'recall' in metrics:
                        print(f"     Recall: {metrics['recall']:.4f}")
                
                # –í—ã–≤–æ–¥–∏–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                target_type = meta.get('target_type', 'unknown')
                horizon = meta.get('horizon', 0)
                if target_type != 'unknown':
                    print(f"     –¢–∞—Ä–≥–µ—Ç: {target_type}, –≥–æ—Ä–∏–∑–æ–Ω—Ç: {horizon}")
                
                model_score = meta.get('model_score', 0)
                if model_score > 0:
                    print(f"     –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {model_score:.4f}")
                
                print()
                
            except Exception as e:
                print(f"   {model_dir}: –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö - {e}")

def get_model_info(symbol: str, task: str = 'regression'):
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
    print(f"üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ {symbol} ({task})")
    print("=" * 50)
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = Config(
        models_root='models',
        data_root='data',
        log_level='INFO'
    )
    
    try:
        if task == 'regression':
            system = RegressionSystem(config)
        else:
            system = ClassificationSystem(config)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        model_info = system.get_model_info(symbol)
        if model_info:
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ–Ω–∞:")
            print(f"   –°–∏–º–≤–æ–ª: {model_info['symbol']}")
            print(f"   –ó–∞–¥–∞—á–∞: {model_info['task']}")
            print(f"   –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_info['model_type']}")
            print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {model_info['features_count']}")
            print(f"   –î–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è: {model_info['training_date']}")
            
            print(f"\nüìà –ú–µ—Ç—Ä–∏–∫–∏:")
            for metric, value in model_info['metrics'].items():
                print(f"   {metric.upper()}: {value:.6f}")
            
            if task == 'regression':
                print(f"\nüéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–∞—Ä–≥–µ—Ç–∞:")
                print(f"   –¢–∏–ø: {model_info['target_type']}")
                print(f"   –ì–æ—Ä–∏–∑–æ–Ω—Ç: {model_info['horizon']}")
            else:
                print(f"\nüéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
                print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–æ—Å—Ç–∞: {model_info['target_percent']*100}%")
                print(f"   –ì–æ—Ä–∏–∑–æ–Ω—Ç: {model_info['horizon']}")
            
            print(f"\n‚≠ê –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {model_info['model_score']:.4f}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤–µ—Ä—Å–∏–π
            history = system.get_model_history(symbol)
            if history and len(history) > 1:
                print(f"\nüìö –ò—Å—Ç–æ—Ä–∏—è –≤–µ—Ä—Å–∏–π:")
                for i, version in enumerate(history[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –≤–µ—Ä—Å–∏–π
                    print(f"   v{version['version']}: {version['score']:.4f}")
        else:
            print(f"‚ùå –ú–æ–¥–µ–ª—å {symbol} ({task}) –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")

def main():
    parser = argparse.ArgumentParser(description='üöÄ –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏')
    parser.add_argument('action', choices=['train', 'list', 'info'], 
                       help='–î–µ–π—Å—Ç–≤–∏–µ: train - –æ–±—É—á–µ–Ω–∏–µ, list - —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, info - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--symbol', '-s', default='SOL_USDT',
                       help='–°–∏–º–≤–æ–ª –º–æ–Ω–µ—Ç—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: SOL_USDT)')
    parser.add_argument('--task', '-t', choices=['regression', 'classification'], 
                       default='regression', help='–¢–∏–ø –∑–∞–¥–∞—á–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: regression)')
    parser.add_argument('--target', choices=['crypto_clipped', 'volume_weighted', 'vol_regime', 'market_regime', 'momentum_enhanced', 'volume_volatility'],
                       default='crypto_clipped', help='–¢–∏–ø —Ç–∞—Ä–≥–µ—Ç–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: crypto_clipped)')
    parser.add_argument('--percent', type=float, default=0.025,
                       help='–ü—Ä–æ—Ü–µ–Ω—Ç —Ä–æ—Å—Ç–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.025 = 2.5%)')
    parser.add_argument('--horizon', type=int, default=10,
                       help='–ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –±–∞—Ä–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 10)')
    parser.add_argument('--timeframes', nargs='+', 
                       default=['15m', '1h', '4h', '1d'],
                       help='–¢–∞–π–º—Ñ—Ä–µ–π–º—ã –¥–ª—è multi-timeframe –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')
    parser.add_argument('--trials', type=int, default=50,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ Optuna trials (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 50)')
    
    args = parser.parse_args()
    
    if args.action == 'list':
        list_available_models()
        return
    
    if args.action == 'info':
        get_model_info(args.symbol, args.task)
        return
    
    if args.action == 'train':
        print("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏")
        print("=" * 50)
        
        if args.task == 'regression':
            success = train_regression_model(
                symbol=args.symbol,
                target_type=args.target,
                horizon=args.horizon,
                timeframes=args.timeframes,
                n_trials=args.trials
            )
        else:  # classification
            success = train_classification_model(
                symbol=args.symbol,
                percent=args.percent,
                horizon=args.horizon,
                n_trials=args.trials
            )
        
        if success:
            print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            sys.exit(0)
        else:
            print("\n‚ùå –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –æ—à–∏–±–∫–∞–º–∏")
            sys.exit(1)

if __name__ == "__main__":
    import numpy as np
    main() 