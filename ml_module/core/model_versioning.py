#!/usr/bin/env python3
"""
üìö ModelVersioning - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π

–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–µ—Ä—Å–∏—è–º–∏ –º–æ–¥–µ–ª–µ–π —Å —É–º–Ω—ã–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π.
"""

import os
import json
import shutil
import hashlib
import pickle
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Tuple, List, Union
from pathlib import Path
import logging

class ModelVersioning:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π —Å —É–º–Ω—ã–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫.
    –í–∫–ª—é—á–∞–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—á–∏—Å—Ç–∫—É –∏ –≤–µ—Å–∞ –º–µ—Ç—Ä–∏–∫.
    """
    
    def __init__(self, models_root: str = 'models', 
                 min_improvement: float = 0.001,
                 max_backups: int = 10,
                 cleanup_days: int = 30):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        
        Args:
            models_root: –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π
            min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è –∑–∞–º–µ–Ω—ã –º–æ–¥–µ–ª–∏ (0.001 = 0.1%)
            max_backups: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
            cleanup_days: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è—Ç—å –≤–µ—Ä—Å–∏–∏ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
        """
        self.models_root = Path(models_root)
        self.models_root.mkdir(parents=True, exist_ok=True)
        
        self.min_improvement = min_improvement
        self.max_backups = max_backups
        self.cleanup_days = cleanup_days
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
        
        # –í–µ—Å–∞ –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (—Å—É–º–º–∞ = 1.0)
        self.regression_weights = {
            'rmse': 0.4,    # RMSE - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π
            'mae': 0.3,     # MAE - —Å—Ä–µ–¥–Ω–∏–π –≤–µ—Å
            'r2': 0.3       # R¬≤ - —Å—Ä–µ–¥–Ω–∏–π –≤–µ—Å
        }
        
        # –í–µ—Å–∞ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.classification_weights = {
            'accuracy': 0.5,  # Accuracy - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π
            'f1': 0.5         # F1 - —Ä–∞–≤–Ω—ã–π –≤–µ—Å
        }
    
    def get_model_paths(self, symbol: str, modeltype: str = 'regression') -> Dict[str, Path]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –º–æ–¥–µ–ª–∏"""
        symbol = symbol.upper().replace('/', '')
        base = self.models_root / symbol / modeltype
        
        return {
            'base': base,
            'model': base / 'model.pkl',
            'meta': base / 'meta.json',
            'backup_dir': base / 'backups',
            'validation': base / 'validation.json'
        }
    
    def validate_model_files(self, symbol: str, modeltype: str = 'regression') -> Tuple[bool, str]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏
        
        Returns:
            (is_valid, error_message)
        """
        paths = self.get_model_paths(symbol, modeltype)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        if not paths['model'].exists():
            return False, f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {paths['model']}"
        
        if not paths['meta'].exists():
            return False, f"–§–∞–π–ª –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {paths['meta']}"
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
            with open(paths['model'], 'rb') as f:
                model = pickle.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            with open(paths['meta'], 'r') as f:
                meta = json.load(f)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            required_fields = ['metrics', 'model_type', 'features', 'saved_at']
            for field in required_fields:
                if field not in meta:
                    return False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {field}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            if hasattr(model, 'predict'):
                # –¢–µ—Å—Ç–æ–≤–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                import numpy as np
                test_data = np.random.random((1, len(meta.get('features', []))))
                try:
                    _ = model.predict(test_data)
                except Exception as e:
                    return False, f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}"
            else:
                return False, "–ú–æ–¥–µ–ª—å –Ω–µ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥–∞ predict"
            
            return True, "–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ"
            
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}"
    
    def calculate_model_score(self, metrics: Dict[str, Any], task_type: str = 'regression') -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π —Å–∫–æ—Ä –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        
        Args:
            metrics: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏ ('regression' –∏–ª–∏ 'classification')
            
        Returns:
            –û–±—â–∏–π —Å–∫–æ—Ä –º–æ–¥–µ–ª–∏ (—á–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ)
        """
        if task_type == 'regression':
            weights = self.regression_weights
            rmse = metrics.get('rmse', float('inf'))
            mae = metrics.get('mae', float('inf'))
            r2 = metrics.get('r2', -float('inf'))
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ (RMSE –∏ MAE - —á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
            # R¬≤ - —á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ
            if rmse == float('inf'):
                rmse_score = 0
            else:
                rmse_score = 1.0 / (1.0 + rmse)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è RMSE
            
            if mae == float('inf'):
                mae_score = 0
            else:
                mae_score = 1.0 / (1.0 + mae)    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è MAE
            
            r2_score = max(0, r2)  # R¬≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω—å—à–µ 0
            
            # –í—ã—á–∏—Å–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π —Å–∫–æ—Ä
            score = (weights['rmse'] * rmse_score + 
                    weights['mae'] * mae_score + 
                    weights['r2'] * r2_score)
            
        else:  # classification
            weights = self.classification_weights
            accuracy = metrics.get('accuracy', 0)
            f1 = metrics.get('f1', 0)
            
            score = (weights['accuracy'] * accuracy + 
                    weights['f1'] * f1)
        
        return score
    
    def compare_models_advanced(self, current_metrics: Optional[Dict[str, Any]], 
                              new_metrics: Dict[str, Any], 
                              task_type: str = 'regression') -> Tuple[bool, str, float]:
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å —É—á–µ—Ç–æ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è
        
        Args:
            current_metrics: –ú–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
            new_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏
            
        Returns:
            (is_better, reason, improvement_percent)
        """
        if current_metrics is None:
            return True, "–ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å", 100.0
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–µ —Å–∫–æ—Ä—ã
        current_score = self.calculate_model_score(current_metrics.get('metrics', {}), task_type)
        new_score = self.calculate_model_score(new_metrics.get('metrics', {}), task_type)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —É–ª—É—á—à–µ–Ω–∏—è
        if current_score == 0:
            improvement_percent = 100.0 if new_score > 0 else 0.0
        else:
            improvement_percent = ((new_score - current_score) / current_score) * 100
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
        if improvement_percent < (self.min_improvement * 100):
            return False, f"–£–ª—É—á—à–µ–Ω–∏–µ {improvement_percent:.2f}% –º–µ–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ {self.min_improvement * 100:.2f}%", improvement_percent
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        if task_type == 'regression':
            current_rmse = current_metrics.get('metrics', {}).get('rmse', float('inf'))
            current_r2 = current_metrics.get('metrics', {}).get('r2', -float('inf'))
            current_mae = current_metrics.get('metrics', {}).get('mae', float('inf'))
            
            new_rmse = new_metrics.get('metrics', {}).get('rmse', float('inf'))
            new_r2 = new_metrics.get('metrics', {}).get('r2', -float('inf'))
            new_mae = new_metrics.get('metrics', {}).get('mae', float('inf'))
            
            improvements = []
            if new_rmse < current_rmse:
                rmse_improvement = ((current_rmse - new_rmse) / current_rmse) * 100
                improvements.append(f"RMSE: {current_rmse:.4f} ‚Üí {new_rmse:.4f} (-{rmse_improvement:.2f}%)")
            if new_r2 > current_r2:
                r2_improvement = ((new_r2 - current_r2) / abs(current_r2)) * 100
                improvements.append(f"R¬≤: {current_r2:.4f} ‚Üí {new_r2:.4f} (+{r2_improvement:.2f}%)")
            if new_mae < current_mae:
                mae_improvement = ((current_mae - new_mae) / current_mae) * 100
                improvements.append(f"MAE: {current_mae:.4f} ‚Üí {new_mae:.4f} (-{mae_improvement:.2f}%)")
            
            reason = f"–û–±—â–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {improvement_percent:.2f}%. " + ", ".join(improvements)
            
        else:  # classification
            current_accuracy = current_metrics.get('metrics', {}).get('accuracy', 0)
            current_f1 = current_metrics.get('metrics', {}).get('f1', 0)
            
            new_accuracy = new_metrics.get('metrics', {}).get('accuracy', 0)
            new_f1 = new_metrics.get('metrics', {}).get('f1', 0)
            
            improvements = []
            if new_accuracy > current_accuracy:
                acc_improvement = ((new_accuracy - current_accuracy) / current_accuracy) * 100
                improvements.append(f"Accuracy: {current_accuracy:.4f} ‚Üí {new_accuracy:.4f} (+{acc_improvement:.2f}%)")
            if new_f1 > current_f1:
                f1_improvement = ((new_f1 - current_f1) / current_f1) * 100
                improvements.append(f"F1: {current_f1:.4f} ‚Üí {new_f1:.4f} (+{f1_improvement:.2f}%)")
            
            reason = f"–û–±—â–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {improvement_percent:.2f}%. " + ", ".join(improvements)
        
        return True, reason, improvement_percent
    
    def cleanup_old_versions(self, symbol: str, modeltype: str = 'regression') -> int:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–µ–π
        
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏–π
        """
        paths = self.get_model_paths(symbol, modeltype)
        
        if not paths['backup_dir'].exists():
            return 0
        
        cutoff_date = datetime.now() - timedelta(days=self.cleanup_days)
        deleted_count = 0
        
        for backup_dir in paths['backup_dir'].iterdir():
            if not backup_dir.is_dir():
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è
            try:
                meta_path = backup_dir / 'meta.json'
                if meta_path.exists():
                    with open(meta_path, 'r') as f:
                        meta = json.load(f)
                    
                    saved_at = datetime.fromisoformat(meta.get('saved_at', '2000-01-01T00:00:00'))
                    
                    if saved_at < cutoff_date:
                        shutil.rmtree(backup_dir)
                        deleted_count += 1
                        self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è: {backup_dir.name}")
                        
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {backup_dir}: {e}")
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä—Å–∏–π
        if paths['backup_dir'].exists():
            backup_dirs = sorted([d for d in paths['backup_dir'].iterdir() if d.is_dir()], 
                               key=lambda x: x.name, reverse=True)
            
            if len(backup_dirs) > self.max_backups:
                for old_backup in backup_dirs[self.max_backups:]:
                    shutil.rmtree(old_backup)
                    deleted_count += 1
                    self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ª–∏—à–Ω—è—è –≤–µ—Ä—Å–∏—è: {old_backup.name}")
        
        return deleted_count
    
    def load_current_model_metrics(self, symbol: str, modeltype: str = 'regression') -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        paths = self.get_model_paths(symbol, modeltype)
        
        if not paths['meta'].exists():
            return None
        
        try:
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
            is_valid, error_msg = self.validate_model_files(symbol, modeltype)
            if not is_valid:
                self.logger.warning(f"‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞: {error_msg}")
                return None
            
            with open(paths['meta'], 'r') as f:
                meta = json.load(f)
            return meta
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def backup_current_model(self, symbol: str, modeltype: str = 'regression') -> bool:
        """–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        paths = self.get_model_paths(symbol, modeltype)
        
        if not paths['model'].exists() or not paths['meta'].exists():
            return True  # –ù–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ backup
        is_valid, error_msg = self.validate_model_files(symbol, modeltype)
        if not is_valid:
            self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å backup - –º–æ–¥–µ–ª—å –Ω–µ–≤–∞–ª–∏–¥–Ω–∞: {error_msg}")
            return False
        
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
            paths['backup_dir'].mkdir(parents=True, exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π –∏ —Ö–µ—à–µ–º
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # –°–æ–∑–¥–∞–µ–º —Ö–µ—à –º–æ–¥–µ–ª–∏ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            with open(paths['model'], 'rb') as f:
                model_hash = hashlib.md5(f.read()).hexdigest()[:8]
            
            backup_name = f"backup_{timestamp}_{model_hash}"
            backup_path = paths['backup_dir'] / backup_name
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            backup_path.mkdir(parents=True, exist_ok=True)
            
            # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
            shutil.copy2(paths['model'], backup_path / 'model.pkl')
            shutil.copy2(paths['meta'], backup_path / 'meta.json')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ backup
            backup_info = {
                'backup_created_at': datetime.now().isoformat(),
                'original_path': str(paths['model']),
                'model_hash': model_hash
            }
            
            with open(backup_path / 'backup_info.json', 'w') as f:
                json.dump(backup_info, f, indent=2)
            
            self.logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return False
    
    def save_model_with_versioning(self, symbol: str, model: Any, features: List[str], 
                                 meta: Dict[str, Any], modeltype: str = 'regression') -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π.
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª—å—é –∏ –∑–∞–º–µ–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–æ–≤–∞—è –ª—É—á—à–µ.
        """
        paths = self.get_model_paths(symbol, modeltype)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏
        task_type = 'classification' if 'accuracy' in meta.get('metrics', {}) else 'regression'
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
        current_metrics = self.load_current_model_metrics(symbol, modeltype)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
        is_better, reason, improvement = self.compare_models_advanced(current_metrics, meta, task_type)
        
        self.logger.info(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è {symbol}: {reason}")
        
        if not is_better:
            self.logger.warning(f"‚ö†Ô∏è –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å —Ö—É–∂–µ —Ç–µ–∫—É—â–µ–π –¥–ª—è {symbol}. –ú–æ–¥–µ–ª—å –ù–ï –±—É–¥–µ—Ç –∑–∞–º–µ–Ω–µ–Ω–∞.")
            return False
        
        # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
        if current_metrics:
            if not self.backup_current_model(symbol, modeltype):
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é. –ú–æ–¥–µ–ª—å –ù–ï –±—É–¥–µ—Ç –∑–∞–º–µ–Ω–µ–Ω–∞.")
                return False
        
        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        paths['base'].mkdir(parents=True, exist_ok=True)
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            meta['features'] = features
            meta['saved_at'] = datetime.now().isoformat()
            meta['version'] = self._get_next_version(symbol, modeltype)
            meta['task_type'] = task_type
            meta['model_score'] = self.calculate_model_score(meta.get('metrics', {}), task_type)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            with open(paths['model'], 'wb') as f:
                pickle.dump(model, f)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            with open(paths['meta'], 'w') as f:
                json.dump(meta, f, indent=2)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            validation_info = {
                'last_validation': datetime.now().isoformat(),
                'validation_passed': True,
                'model_score': meta['model_score'],
                'improvement_percent': improvement
            }
            
            with open(paths['validation'], 'w') as f:
                json.dump(validation_info, f, indent=2)
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
            deleted_count = self.cleanup_old_versions(symbol, modeltype)
            if deleted_count > 0:
                self.logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π")
            
            self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {paths['model']}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def _get_next_version(self, symbol: str, modeltype: str = 'regression') -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä –≤–µ—Ä—Å–∏–∏"""
        paths = self.get_model_paths(symbol, modeltype)
        
        if not paths['backup_dir'].exists():
            return "1.0"
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤–µ—Ä—Å–∏–∏
        existing_versions = [d.name for d in paths['backup_dir'].iterdir() if d.is_dir()]
        version_number = len(existing_versions) + 1
        
        return f"{version_number}.0"
    
    def get_model_history(self, symbol: str, modeltype: str = 'regression') -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–∏"""
        paths = self.get_model_paths(symbol, modeltype)
        
        history = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
        current_metrics = self.load_current_model_metrics(symbol, modeltype)
        if current_metrics:
            history.append({
                'version': 'current',
                'saved_at': current_metrics.get('saved_at', 'unknown'),
                'metrics': current_metrics.get('metrics', {}),
                'model_type': current_metrics.get('model_type', 'unknown'),
                'model_score': current_metrics.get('model_score', 0),
                'task_type': current_metrics.get('task_type', 'unknown'),
                'features_count': len(current_metrics.get('features', []))
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
        if paths['backup_dir'].exists():
            for backup_dir in sorted(paths['backup_dir'].iterdir(), key=lambda x: x.name, reverse=True):
                if backup_dir.is_dir():
                    meta_path = backup_dir / 'meta.json'
                    if meta_path.exists():
                        try:
                            with open(meta_path, 'r') as f:
                                meta = json.load(f)
                            
                            history.append({
                                'version': backup_dir.name,
                                'saved_at': meta.get('saved_at', 'unknown'),
                                'metrics': meta.get('metrics', {}),
                                'model_type': meta.get('model_type', 'unknown'),
                                'model_score': meta.get('model_score', 0),
                                'task_type': meta.get('task_type', 'unknown'),
                                'features_count': len(meta.get('features', []))
                            })
                        except Exception as e:
                            self.logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö {meta_path}: {e}")
        
        return history
    
    def restore_model_version(self, symbol: str, version: str, modeltype: str = 'regression') -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        paths = self.get_model_paths(symbol, modeltype)
        
        if version == 'current':
            self.logger.info("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è - —ç—Ç–æ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å")
            return True
        
        backup_path = paths['backup_dir'] / version
        if not backup_path.exists():
            self.logger.error(f"‚ùå –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è {version} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return False
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å backup
            backup_model_path = backup_path / 'model.pkl'
            backup_meta_path = backup_path / 'meta.json'
            
            if not backup_model_path.exists() or not backup_meta_path.exists():
                self.logger.error(f"‚ùå Backup {version} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω - –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã")
                return False
            
            # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
            self.backup_current_model(symbol, modeltype)
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã
            shutil.copy2(backup_model_path, paths['model'])
            shutil.copy2(backup_meta_path, paths['meta'])
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            is_valid, error_msg = self.validate_model_files(symbol, modeltype)
            if not is_valid:
                self.logger.error(f"‚ùå –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–≤–∞–ª–∏–¥–Ω–∞: {error_msg}")
                return False
            
            self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ {version}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def list_models(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        models = []
        
        for symbol_dir in self.models_root.iterdir():
            if symbol_dir.is_dir():
                symbol = symbol_dir.name
                
                for modeltype_dir in symbol_dir.iterdir():
                    if modeltype_dir.is_dir():
                        modeltype = modeltype_dir.name
                        
                        meta_path = modeltype_dir / 'meta.json'
                        if meta_path.exists():
                            try:
                                with open(meta_path, 'r') as f:
                                    meta = json.load(f)
                                
                                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
                                is_valid, _ = self.validate_model_files(symbol, modeltype)
                                
                                models.append({
                                    'symbol': symbol,
                                    'type': modeltype,
                                    'model_type': meta.get('model_type', 'unknown'),
                                    'saved_at': meta.get('saved_at', 'unknown'),
                                    'metrics': meta.get('metrics', {}),
                                    'model_score': meta.get('model_score', 0),
                                    'task_type': meta.get('task_type', 'unknown'),
                                    'features_count': len(meta.get('features', [])),
                                    'is_valid': is_valid,
                                    'backup_count': len([d for d in (modeltype_dir / 'backups').iterdir() 
                                                       if d.is_dir()]) if (modeltype_dir / 'backups').exists() else 0
                                })
                            except Exception as e:
                                self.logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö {meta_path}: {e}")
        
        return models
    
    def get_model_statistics(self, symbol: str, modeltype: str = 'regression') -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –º–æ–¥–µ–ª–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –º–æ–¥–µ–ª–∏
        """
        history = self.get_model_history(symbol, modeltype)
        
        if not history:
            return {'error': '–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}
        
        current_model = history[0] if history[0]['version'] == 'current' else None
        backup_models = [m for m in history if m['version'] != 'current']
        
        stats = {
            'symbol': symbol,
            'modeltype': modeltype,
            'current_model': current_model,
            'total_versions': len(history),
            'backup_count': len(backup_models),
            'first_version': backup_models[-1] if backup_models else None,
            'latest_backup': backup_models[0] if backup_models else None,
            'score_trend': [m['model_score'] for m in history],
            'improvement_history': []
        }
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —É–ª—É—á—à–µ–Ω–∏–π
        for i in range(1, len(history)):
            prev_score = history[i]['model_score']
            curr_score = history[i-1]['model_score']
            
            if prev_score > 0:
                improvement = ((curr_score - prev_score) / prev_score) * 100
                stats['improvement_history'].append({
                    'from_version': history[i]['version'],
                    'to_version': history[i-1]['version'],
                    'improvement_percent': improvement
                })
        
        return stats 