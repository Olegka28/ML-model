#!/usr/bin/env python3
"""
ü§ñ ModelManager - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏

–û–±—É—á–µ–Ω–∏–µ, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∑–∫–∞, –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (XGBoost, LightGBM, CatBoost).
"""

import os
import sys
import json
import pickle
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime
import numpy as np
import pandas as pd
import mlflow
import mlflow.xgboost
import mlflow.lightgbm
import mlflow.catboost

from ..utils.config import Config
from ..utils.logger import Logger
from ..utils.validators import ModelValidator, ValidationError
from .model_versioning import ModelVersioning
from .baseline import BaselineModels

class ModelManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π ML —Å–∏—Å—Ç–µ–º—ã
    - –û–±—É—á–µ–Ω–∏–µ (XGBoost, LightGBM, CatBoost)
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    - –í–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MLflow
    """
    def __init__(self, config: Config):
        self.config = config
        self.models_root = Path(config.models_root)
        self.models_root.mkdir(parents=True, exist_ok=True)
        self.logger = Logger('ModelManager', level=config.log_level)
        self.versioning = ModelVersioning(config.models_root)
        mlflow.set_tracking_uri(config.mlflow_tracking_uri)
        mlflow.set_experiment(config.mlflow_experiment_name)
        self._model_cache = {}

    def validate_input_data(self, X: np.ndarray, y: np.ndarray, task: str = 'regression') -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            X: np.ndarray - –ø—Ä–∏–∑–Ω–∞–∫–∏
            y: np.ndarray - —Ç–∞—Ä–≥–µ—Ç
            task: —Ç–∏–ø –∑–∞–¥–∞—á–∏
            
        Returns:
            True –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–Ω—ã
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            if len(X) != len(y):
                raise ValueError(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ X ({len(X)}) –∏ y ({len(y)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")
            
            if len(X) == 0:
                raise ValueError("–î–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ inf
            if np.any(np.isnan(X)) or np.any(np.isinf(X)):
                raise ValueError("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∏–ª–∏ inf –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö")
            
            if np.any(np.isnan(y)) or np.any(np.isinf(y)):
                raise ValueError("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∏–ª–∏ inf –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ç–∞—Ä–≥–µ—Ç–µ")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            if not isinstance(X, np.ndarray):
                raise ValueError("X –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å numpy.ndarray")
            
            if not isinstance(y, np.ndarray):
                raise ValueError("y –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å numpy.ndarray")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if task == 'classification':
                unique_classes = np.unique(y)
                if len(unique_classes) < 2:
                    raise ValueError("–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –∫–ª–∞—Å—Å–∞")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–ª–∞—Å—Å—ã —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞
                if not np.issubdtype(y.dtype, np.integer):
                    raise ValueError("–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∞—Ä–≥–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ü–µ–ª—ã–º–∏ —á–∏—Å–ª–∞–º–∏")
            
            self.logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ: X={X.shape}, y={y.shape}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def _create_time_series_split(self, X: np.ndarray, y: np.ndarray, 
                                 cv_type: str = 'walk_forward', 
                                 n_splits: int = 5,
                                 test_size: float = 0.2) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ø–ª–∏—Ç—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        
        Args:
            X: –ø—Ä–∏–∑–Ω–∞–∫–∏
            y: —Ç–∞—Ä–≥–µ—Ç
            cv_type: —Ç–∏–ø –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ ('walk_forward', 'time_series_split', 'expanding_window')
            n_splits: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–ª–∏—Ç–æ–≤
            test_size: —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞
            
        Returns:
            X_train, X_val, y_train, y_val
        """
        from sklearn.model_selection import TimeSeriesSplit
        
        if cv_type == 'walk_forward':
            # Walk-Forward CV - —Ä–∞—Å—à–∏—Ä—è—é—â–µ–µ—Å—è –æ–∫–Ω–æ
            return self._walk_forward_split(X, y, n_splits, test_size)
            
        elif cv_type == 'time_series_split':
            # TimeSeriesSplit - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–∫–Ω–æ
            return self._time_series_split(X, y, n_splits)
            
        elif cv_type == 'expanding_window':
            # –†–∞—Å—à–∏—Ä—è—é—â–µ–µ—Å—è –æ–∫–Ω–æ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–µ—Å—Ç–æ–≤—ã–º –Ω–∞–±–æ—Ä–æ–º
            return self._expanding_window_split(X, y, test_size)
            
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø CV: {cv_type}")
    
    def _walk_forward_split(self, X: np.ndarray, y: np.ndarray, 
                           n_splits: int, test_size: float) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        Walk-Forward CV - —Ä–∞—Å—à–∏—Ä—è—é—â–µ–µ—Å—è –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è
        
        –≠—Ç–æ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç, —Ç–∞–∫ –∫–∞–∫:
        1. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–∞—Å—à–∏—Ä—è—é—â–µ–µ—Å—è –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è
        2. –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        3. –ò–º–∏—Ç–∏—Ä—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è
        """
        total_size = len(X)
        test_size_samples = int(total_size * test_size)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        split_point = total_size - test_size_samples
        
        # –û–±—É—á–∞–µ–º –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ split_point
        X_train = X[:split_point]
        y_train = y[:split_point]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö
        X_val = X[split_point:]
        y_val = y[split_point:]
        
        self.logger.info(f"üîÑ Walk-Forward CV: –æ–±—É—á–∞–µ–º –Ω–∞ {len(X_train)} –±–∞—Ä–æ–≤, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(X_val)} –±–∞—Ä–æ–≤")
        self.logger.info(f"üìà –û–±—É—á–∞—é—â–∏–π –ø–µ—Ä–∏–æ–¥: 0 ‚Üí {split_point}, –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥: {split_point} ‚Üí {total_size}")
        
        return X_train, X_val, y_train, y_val
    
    def _time_series_split(self, X: np.ndarray, y: np.ndarray, 
                          n_splits: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        TimeSeriesSplit - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–∫–Ω–æ
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç sklearn TimeSeriesSplit –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ø–ª–∏—Ç–æ–≤
        """
        from sklearn.model_selection import TimeSeriesSplit
        
        tscv = TimeSeriesSplit(n_splits=n_splits)
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ø–ª–∏—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        splits = list(tscv.split(X))
        train_idx, val_idx = splits[-1]
        
        X_train = X[train_idx]
        y_train = y[train_idx]
        X_val = X[val_idx]
        y_val = y[val_idx]
        
        self.logger.info(f"üîÑ TimeSeriesSplit CV: –æ–±—É—á–∞–µ–º –Ω–∞ {len(X_train)} –±–∞—Ä–æ–≤, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(X_val)} –±–∞—Ä–æ–≤")
        self.logger.info(f"üìà –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ø–ª–∏—Ç –∏–∑ {n_splits} —Å–ø–ª–∏—Ç–æ–≤")
        
        return X_train, X_val, y_train, y_val
    
    def _expanding_window_split(self, X: np.ndarray, y: np.ndarray, 
                               test_size: float) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        –†–∞—Å—à–∏—Ä—è—é—â–µ–µ—Å—è –æ–∫–Ω–æ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–µ—Å—Ç–æ–≤—ã–º –Ω–∞–±–æ—Ä–æ–º
        
        –ü–æ—Ö–æ–∂–µ –Ω–∞ Walk-Forward, –Ω–æ —Å –±–æ–ª–µ–µ –≥–∏–±–∫–∏–º –ø–æ–¥—Ö–æ–¥–æ–º
        """
        total_size = len(X)
        test_size_samples = int(total_size * test_size)
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞
        min_train_size = int(total_size * 0.3)  # –ú–∏–Ω–∏–º—É–º 30% –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä—è—é—â–µ–µ—Å—è –æ–∫–Ω–æ
        split_point = max(min_train_size, total_size - test_size_samples)
        
        X_train = X[:split_point]
        y_train = y[:split_point]
        X_val = X[split_point:]
        y_val = y[split_point:]
        
        self.logger.info(f"üîÑ Expanding Window CV: –æ–±—É—á–∞–µ–º –Ω–∞ {len(X_train)} –±–∞—Ä–æ–≤, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(X_val)} –±–∞—Ä–æ–≤")
        self.logger.info(f"üìà –û–±—É—á–∞—é—â–∏–π –ø–µ—Ä–∏–æ–¥: 0 ‚Üí {split_point}, –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥: {split_point} ‚Üí {total_size}")
        
        return X_train, X_val, y_train, y_val
    
    def cross_validate_time_series(self, X: np.ndarray, y: np.ndarray, 
                                 model_config: Optional[dict] = None,
                                 cv_type: str = 'walk_forward',
                                 n_splits: int = 5) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω–∞—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        
        Args:
            X: –ø—Ä–∏–∑–Ω–∞–∫–∏
            y: —Ç–∞—Ä–≥–µ—Ç
            model_config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
            cv_type: —Ç–∏–ø CV
            n_splits: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–ª–∏—Ç–æ–≤
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        from sklearn.model_selection import TimeSeriesSplit
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        if model_config is None:
            model_config = {
                'model_type': self.config.model.model_type,
                'target_type': self.config.model.target_type,
                'horizon': self.config.model.horizon
            }
        
        cv_scores = {
            'rmse': [],
            'mae': [],
            'r2': [],
            'splits': []
        }
        
        if cv_type == 'walk_forward':
            # Walk-Forward CV
            total_size = len(X)
            test_size = int(total_size * 0.2)  # 20% –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            
            for i in range(n_splits):
                # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞
                train_size = int(total_size * (0.3 + 0.1 * i))  # –û—Ç 30% –¥–æ 70%
                train_size = min(train_size, total_size - test_size)
                
                # –°–æ–∑–¥–∞–µ–º —Å–ø–ª–∏—Ç
                X_train = X[:train_size]
                y_train = y[:train_size]
                X_val = X[train_size:train_size + test_size]
                y_val = y[train_size:train_size + test_size]
                
                # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                try:
                    model, _ = self.train_model(X_train, y_train, model_config, 'regression')
                    y_pred = self.predict(model, X_val)
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
                    mae = mean_absolute_error(y_val, y_pred)
                    r2 = r2_score(y_val, y_pred)
                    
                    cv_scores['rmse'].append(rmse)
                    cv_scores['mae'].append(mae)
                    cv_scores['r2'].append(r2)
                    cv_scores['splits'].append({
                        'train_size': len(X_train),
                        'val_size': len(X_val),
                        'train_period': f"0 ‚Üí {train_size}",
                        'val_period': f"{train_size} ‚Üí {train_size + test_size}"
                    })
                    
                    self.logger.info(f"üîÑ –°–ø–ª–∏—Ç {i+1}/{n_splits}: RMSE={rmse:.4f}, MAE={mae:.4f}, R¬≤={r2:.4f}")
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Å–ø–ª–∏—Ç–µ {i+1}: {e}")
                    continue
                    
        elif cv_type == 'time_series_split':
            # TimeSeriesSplit
            tscv = TimeSeriesSplit(n_splits=n_splits)
            
            for i, (train_idx, val_idx) in enumerate(tscv.split(X)):
                X_train = X[train_idx]
                y_train = y[train_idx]
                X_val = X[val_idx]
                y_val = y[val_idx]
                
                try:
                    model, _ = self.train_model(X_train, y_train, model_config, 'regression')
                    y_pred = self.predict(model, X_val)
                    
                    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
                    mae = mean_absolute_error(y_val, y_pred)
                    r2 = r2_score(y_val, y_pred)
                    
                    cv_scores['rmse'].append(rmse)
                    cv_scores['mae'].append(mae)
                    cv_scores['r2'].append(r2)
                    cv_scores['splits'].append({
                        'train_size': len(X_train),
                        'val_size': len(X_val),
                        'train_period': f"{train_idx[0]} ‚Üí {train_idx[-1]}",
                        'val_period': f"{val_idx[0]} ‚Üí {val_idx[-1]}"
                    })
                    
                    self.logger.info(f"üîÑ –°–ø–ª–∏—Ç {i+1}/{n_splits}: RMSE={rmse:.4f}, MAE={mae:.4f}, R¬≤={r2:.4f}")
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Å–ø–ª–∏—Ç–µ {i+1}: {e}")
                    continue
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if cv_scores['rmse']:
            cv_results = {
                'mean_rmse': np.mean(cv_scores['rmse']),
                'std_rmse': np.std(cv_scores['rmse']),
                'mean_mae': np.mean(cv_scores['mae']),
                'std_mae': np.std(cv_scores['mae']),
                'mean_r2': np.mean(cv_scores['r2']),
                'std_r2': np.std(cv_scores['r2']),
                'n_splits': len(cv_scores['rmse']),
                'splits': cv_scores['splits']
            }
            
            self.logger.info(f"üìä CV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ({cv_type}):")
            self.logger.info(f"   RMSE: {cv_results['mean_rmse']:.4f} ¬± {cv_results['std_rmse']:.4f}")
            self.logger.info(f"   MAE: {cv_results['mean_mae']:.4f} ¬± {cv_results['std_mae']:.4f}")
            self.logger.info(f"   R¬≤: {cv_results['mean_r2']:.4f} ¬± {cv_results['std_r2']:.4f}")
            
            return cv_results
        else:
            self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é")
            return {}
    
    def train_model(self, X: np.ndarray, y: np.ndarray, feature_names: Optional[List[str]] = None, model_config: Optional[dict] = None, task: str = 'regression') -> Tuple[Any, Dict]:
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (XGBoost/LightGBM/CatBoost)
        Args:
            X: np.ndarray - –ø—Ä–∏–∑–Ω–∞–∫–∏
            y: np.ndarray - —Ç–∞—Ä–≥–µ—Ç
            feature_names: List[str] - –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            model_config: dict - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
            task: 'regression' –∏–ª–∏ 'classification'
        Returns:
            model, metadata
        """
        import xgboost as xgb
        import lightgbm as lgb
        from catboost import CatBoostRegressor, CatBoostClassifier
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score
        import optuna

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.validate_input_data(X, y, task)

        if model_config is None:
            model_config = {
                'model_type': self.config.model.model_type,
                'target_type': self.config.model.target_type,
                'horizon': self.config.model.horizon,
                'n_trials': self.config.model.n_trials,
                'early_stopping_rounds': self.config.model.early_stopping_rounds,
                'random_state': self.config.model.random_state
            }
        model_type = model_config.get('model_type', 'xgboost')
        n_trials = model_config.get('n_trials', 50)
        early_stopping = model_config.get('early_stopping_rounds', 20)
        random_state = model_config.get('random_state', 42)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        if self.config.model.use_time_series_cv:
            # TimeSeriesSplit –∏–ª–∏ Walk-Forward CV
            X_train, X_val, y_train, y_val = self._create_time_series_split(
                X, y, 
                self.config.model.cv_type,
                self.config.model.cv_n_splits,
                self.config.model.cv_test_size
            )
        else:
            # –û–±—ã—á–Ω—ã–π train/test split
            train_size = int(len(X) * self.config.model.train_test_split)
            X_train, X_val = X[:train_size], X[train_size:]
            y_train, y_val = y[:train_size], y[train_size:]
        
        self.logger.info(f"üìä Train: {X_train.shape}, Val: {X_val.shape}")
        self.logger.info(f"üìÖ –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {len(X_train)} ‚Üí {len(X_val)} –±–∞—Ä–æ–≤")

        def xgb_objective(trial):
            params = {
                'objective': 'reg:squarederror' if task == 'regression' else 'binary:logistic',
                'n_estimators': trial.suggest_int('n_estimators', 100, 500),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
                'max_depth': trial.suggest_int('max_depth', 3, 10),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'random_state': random_state
            }
            model = xgb.XGBRegressor(**params) if task == 'regression' else xgb.XGBClassifier(**params)
            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=early_stopping, verbose=False)
            y_pred = model.predict(X_val)
            if task == 'regression':
                return mean_squared_error(y_val, y_pred, squared=False)
            else:
                return 1 - accuracy_score(y_val, (y_pred > 0.5).astype(int))

        def lgb_objective(trial):
            params = {
                'objective': 'regression' if task == 'regression' else 'binary',
                'n_estimators': trial.suggest_int('n_estimators', 100, 500),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
                'max_depth': trial.suggest_int('max_depth', 3, 10),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'random_state': random_state
            }
            model = lgb.LGBMRegressor(**params) if task == 'regression' else lgb.LGBMClassifier(**params)
            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(early_stopping)], verbose=False)
            y_pred = model.predict(X_val)
            if task == 'regression':
                return mean_squared_error(y_val, y_pred, squared=False)
            else:
                return 1 - accuracy_score(y_val, (y_pred > 0.5).astype(int))

        def cat_objective(trial):
            params = {
                'iterations': trial.suggest_int('iterations', 100, 500),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
                'depth': trial.suggest_int('depth', 3, 10),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'random_seed': random_state,
                'loss_function': 'RMSE' if task == 'regression' else 'Logloss',
                'verbose': False
            }
            model = CatBoostRegressor(**params) if task == 'regression' else CatBoostClassifier(**params)
            model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=early_stopping, verbose=False)
            y_pred = model.predict(X_val)
            if task == 'regression':
                return mean_squared_error(y_val, y_pred, squared=False)
            else:
                return 1 - accuracy_score(y_val, (y_pred > 0.5).astype(int))

        # Optuna hyperparameter tuning
        if model_type == 'xgboost':
            study = optuna.create_study(direction='minimize')
            study.optimize(xgb_objective, n_trials=n_trials)
            best_params = study.best_params
            best_params['objective'] = 'reg:squarederror' if task == 'regression' else 'binary:logistic'
            best_params['random_state'] = random_state
            model = xgb.XGBRegressor(**best_params) if task == 'regression' else xgb.XGBClassifier(**best_params)
        elif model_type == 'lightgbm':
            study = optuna.create_study(direction='minimize')
            study.optimize(lgb_objective, n_trials=n_trials)
            best_params = study.best_params
            best_params['objective'] = 'regression' if task == 'regression' else 'binary'
            best_params['random_state'] = random_state
            model = lgb.LGBMRegressor(**best_params) if task == 'regression' else lgb.LGBMClassifier(**best_params)
        elif model_type == 'catboost':
            study = optuna.create_study(direction='minimize')
            study.optimize(cat_objective, n_trials=n_trials)
            best_params = study.best_params
            best_params['loss_function'] = 'RMSE' if task == 'regression' else 'Logloss'
            best_params['random_seed'] = random_state
            model = CatBoostRegressor(**best_params) if task == 'regression' else CatBoostClassifier(**best_params)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")

        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        model.fit(X_train, y_train, eval_set=[(X_val, y_val)] if model_type != 'catboost' else (X_val, y_val), verbose=False)
        y_pred = model.predict(X_val)
        if task == 'regression':
            metrics = {
                'rmse': float(mean_squared_error(y_val, y_pred, squared=False)),
                'mae': float(mean_absolute_error(y_val, y_pred)),
                'r2': float(r2_score(y_val, y_pred)),
            }
        else:
            metrics = {
                'accuracy': float(accuracy_score(y_val, (y_pred > 0.5).astype(int))),
                'f1': float(f1_score(y_val, (y_pred > 0.5).astype(int))),
            }
        # Baseline
        baseline_models = BaselineModels()
        if task == 'regression':
            baseline_report = baseline_models.create_baseline_report(X_train, y_train, X_val, y_val, 'regression')
            baseline = {
                baseline_report['best_baseline']['name']: baseline_report['best_baseline']['metrics']
            }
        else:
            baseline_report = baseline_models.create_baseline_report(X_train, y_train, X_val, y_val, 'classification')
            baseline = {
                baseline_report['best_baseline']['name']: baseline_report['best_baseline']['metrics']
            }
        # MLflow logging
        with mlflow.start_run(run_name=f"{model_type}_{task}"):
            mlflow.log_params(best_params)
            for k, v in metrics.items():
                mlflow.log_metric(k, v)
            mlflow.log_param('task', task)
            mlflow.log_param('train_size', len(y_train))
            mlflow.log_param('val_size', len(y_val))
            mlflow.log_param('baseline', str(baseline))
            if model_type == 'xgboost':
                mlflow.xgboost.log_model(model, "model")
            elif model_type == 'lightgbm':
                mlflow.lightgbm.log_model(model, "model")
            elif model_type == 'catboost':
                mlflow.catboost.log_model(model, "model")
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'model_type': model_type,
            'task': task,
            'symbol': 'SOL_USDT',  # –ë—É–¥–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
            'target_type': model_config.get('target_type', self.config.model.target_type),
            'horizon': model_config.get('horizon', self.config.model.horizon),
            'features': feature_names if feature_names is not None else list(range(X.shape[1])),
            'features_count': X.shape[1],
            'best_params': best_params,
            'metrics': metrics,
            'baseline': baseline,
            'train_size': len(y_train),
            'val_size': len(y_val),
            'train_date': datetime.now().isoformat(),
        }
        self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. –ú–µ—Ç—Ä–∏–∫–∏: {metrics}")
        return model, metadata

    def save_model(self, model: Any, metadata: Dict[str, Any], symbol: str, task: str = 'regression') -> str:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        """
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–∏–º–≤–æ–ª–µ
        metadata['symbol'] = symbol
        metadata['task'] = task
        
        model_dir = self.models_root / symbol / task
        model_dir.mkdir(parents=True, exist_ok=True)
        model_path = model_dir / 'model.pkl'
        meta_path = model_dir / 'meta.json'
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)
        with open(meta_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        # –í–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        if self.config.model.version_model:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            features = metadata.get('selected_features', [])
            if not features and 'features' in metadata:
                features = metadata['features']
            self.versioning.save_model_with_versioning(symbol, model, features, metadata, task)
        self.logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        return str(model_path)
    
    def export_model(self, symbol: str, task: str = 'regression', 
                    export_format: str = 'pickle', export_path: Optional[str] = None) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
        
        Args:
            symbol: —Å–∏–º–≤–æ–ª –º–æ–¥–µ–ª–∏
            task: —Ç–∏–ø –∑–∞–¥–∞—á–∏
            export_format: —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ ('pickle', 'onnx', 'json')
            export_path: –ø—É—Ç—å –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –ü—É—Ç—å –∫ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model, metadata = self.load_model(symbol, task, use_cache=False)
            
            if export_path is None:
                export_path = f"exported_models/{symbol}_{task}_{export_format}"
            
            os.makedirs(os.path.dirname(export_path), exist_ok=True)
            
            if export_format == 'pickle':
                # –≠–∫—Å–ø–æ—Ä—Ç –≤ pickle
                with open(f"{export_path}.pkl", 'wb') as f:
                    pickle.dump(model, f)
                
                # –≠–∫—Å–ø–æ—Ä—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                with open(f"{export_path}_metadata.json", 'w') as f:
                    json.dump(metadata, f, indent=2)
                
                self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ pickle: {export_path}.pkl")
                return f"{export_path}.pkl"
                
            elif export_format == 'json':
                # –≠–∫—Å–ø–æ—Ä—Ç —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ JSON
                with open(f"{export_path}.json", 'w') as f:
                    json.dump(metadata, f, indent=2)
                
                self.logger.info(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ JSON: {export_path}.json")
                return f"{export_path}.json"
                
            elif export_format == 'onnx':
                # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
                try:
                    import onnx
                    from skl2onnx import convert_sklearn
                    from skl2onnx.common.data_types import FloatTensorType
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    input_type = FloatTensorType([None, metadata.get('features_count', 5)])
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
                    onx = convert_sklearn(model, initial_types=[('input', input_type)])
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ONNX –º–æ–¥–µ–ª—å
                    with open(f"{export_path}.onnx", "wb") as f:
                        f.write(onx.SerializeToString())
                    
                    self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ ONNX: {export_path}.onnx")
                    return f"{export_path}.onnx"
                    
                except ImportError:
                    self.logger.error("‚ùå ONNX —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install onnx skl2onnx")
                    raise ValueError("ONNX —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                    
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞: {export_format}")
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def load_model(self, symbol: str, task: str = 'regression', use_cache: bool = True) -> Tuple[Any, Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        
        Args:
            symbol: —Å–∏–º–≤–æ–ª –º–æ–¥–µ–ª–∏
            task: —Ç–∏–ø –∑–∞–¥–∞—á–∏
            use_cache: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
            
        Returns:
            (model, metadata)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if use_cache:
            cached_result = self.get_cached_model(symbol, task)
            if cached_result:
                return cached_result
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å –¥–∏—Å–∫–∞
        model_dir = self.models_root / symbol / task
        model_path = model_dir / 'model.pkl'
        meta_path = model_dir / 'meta.json'
        
        if not model_path.exists() or not meta_path.exists():
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –∏–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {symbol} ({task})")
        
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        with open(meta_path, 'r') as f:
            metadata = json.load(f)
        
        ModelValidator.validate_metadata(metadata)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        if use_cache:
            self.cache_model(symbol, task, model, metadata)
        
        self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
        return model, metadata

    def predict(self, model: Any, X: np.ndarray) -> np.ndarray:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        return model.predict(X)

    def get_model_info(self, symbol: str, task: str = 'regression') -> Optional[Dict[str, Any]]:
        try:
            _, metadata = self.load_model(symbol, task)
            return metadata
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏: {e}")
            return None

    def compare_models(self, symbol: str, task: str = 'regression') -> Dict[str, Any]:
        try:
            return self.versioning.get_model_statistics(symbol, task)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            return {}

    def get_model_history(self, symbol: str, task: str = 'regression') -> List[Dict[str, Any]]:
        try:
            return self.versioning.get_model_history(symbol, task)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            return []

    def restore_model_version(self, symbol: str, version: str, task: str = 'regression') -> bool:
        try:
            return self.versioning.restore_model_version(symbol, version, task)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Ä—Å–∏–∏: {e}")
            return False

    def get_cached_model(self, symbol: str, task: str = 'regression') -> Optional[Tuple[Any, Dict[str, Any]]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –∫—ç—à–∞
        
        Args:
            symbol: —Å–∏–º–≤–æ–ª –º–æ–¥–µ–ª–∏
            task: —Ç–∏–ø –∑–∞–¥–∞—á–∏
            
        Returns:
            (model, metadata) –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ
        """
        cache_key = f"{symbol}_{task}"
        if cache_key in self._model_cache:
            self.logger.info(f"üì¶ –ú–æ–¥–µ–ª—å {symbol} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –∫—ç—à–∞")
            return self._model_cache[cache_key]
        return None
    
    def cache_model(self, symbol: str, task: str, model: Any, metadata: Dict[str, Any]):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –≤ –∫—ç—à
        
        Args:
            symbol: —Å–∏–º–≤–æ–ª –º–æ–¥–µ–ª–∏
            task: —Ç–∏–ø –∑–∞–¥–∞—á–∏
            model: –º–æ–¥–µ–ª—å
            metadata: –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        """
        cache_key = f"{symbol}_{task}"
        self._model_cache[cache_key] = (model, metadata)
        self.logger.info(f"üíæ –ú–æ–¥–µ–ª—å {symbol} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –∫—ç—à")
    
    def clear_cache(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –º–æ–¥–µ–ª–µ–π"""
        cache_size = len(self._model_cache)
        self._model_cache.clear()
        self.logger.info(f"üóëÔ∏è –ö—ç—à –º–æ–¥–µ–ª–µ–π –æ—á–∏—â–µ–Ω ({cache_size} –º–æ–¥–µ–ª–µ–π)")
    
    def get_cache_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ"""
        return {
            'cache_size': len(self._model_cache),
            'cached_models': list(self._model_cache.keys()),
            'memory_usage': sum(sys.getsizeof(model) + sys.getsizeof(metadata) 
                              for model, metadata in self._model_cache.values())
        }

    def compare_with_baseline(self, symbol: str, task: str = 'regression') -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        
        Args:
            symbol: —Å–∏–º–≤–æ–ª –º–æ–¥–µ–ª–∏
            task: —Ç–∏–ø –∑–∞–¥–∞—á–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model, metadata = self.load_model(symbol, task)
            
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
            baseline_models = BaselineModels()
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ)
            # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_test = np.random.random((100, metadata.get('features_count', 5)))
            y_test = np.random.random(100) if task == 'regression' else np.random.randint(0, 2, 100)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
            y_pred = self.predict(model, X_test)
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –ø–æ –±–∞–∑–æ–≤—ã–º –º–æ–¥–µ–ª—è–º
            baseline_report = baseline_models.create_baseline_report(
                X_test, y_test, X_test, y_test, task
            )
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ª—É—á—à–µ–π –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
            best_baseline_metrics = baseline_report['best_baseline']['metrics']
            model_metrics = metadata.get('metrics', {})
            
            comparison = baseline_models.compare_with_baseline(
                model_metrics, best_baseline_metrics, task
            )
            
            return {
                'model_metrics': model_metrics,
                'baseline_metrics': best_baseline_metrics,
                'baseline_name': baseline_report['best_baseline']['name'],
                'comparison': comparison,
                'all_baselines': baseline_report['all_baselines']
            }
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é: {e}")
            return {}
    
    def get_model_performance_summary(self, symbol: str, task: str = 'regression') -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é —Å–≤–æ–¥–∫—É –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        
        Args:
            symbol: —Å–∏–º–≤–æ–ª –º–æ–¥–µ–ª–∏
            task: —Ç–∏–ø –∑–∞–¥–∞—á–∏
            
        Returns:
            –°–≤–æ–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            model_info = self.get_model_info(symbol, task)
            if not model_info:
                return {'error': '–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}
            
            # –ò—Å—Ç–æ—Ä–∏—è –≤–µ—Ä—Å–∏–π
            history = self.get_model_history(symbol, task)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            versioning_stats = self.compare_models(symbol, task)
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
            baseline_comparison = self.compare_with_baseline(symbol, task)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫—ç—à–µ
            cache_info = self.get_cache_info()
            
            return {
                'model_info': model_info,
                'version_history': history,
                'versioning_stats': versioning_stats,
                'baseline_comparison': baseline_comparison,
                'cache_info': cache_info,
                'summary': {
                    'is_cached': symbol in [key.split('_')[0] for key in cache_info['cached_models']],
                    'total_versions': len(history),
                    'current_score': model_info.get('model_score', 0),
                    'is_better_than_baseline': baseline_comparison.get('comparison', {}).get('is_better_than_baseline', False)
                }
            }
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–æ–¥–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return {'error': str(e)}
    
    def get_info(self) -> Dict[str, Any]:
        return {
            'models_root': str(self.models_root),
            'versioning_enabled': self.config.model.version_model,
            'save_models': self.config.model.save_model,
            'model_cache_size': len(self._model_cache),
            'mlflow_tracking_uri': self.config.mlflow_tracking_uri,
            'mlflow_experiment': self.config.mlflow_experiment_name,
            'cache_info': self.get_cache_info()
        } 