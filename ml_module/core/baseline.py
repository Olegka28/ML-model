#!/usr/bin/env python3
"""
üìä Baseline Models - –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

–ú–æ–¥—É–ª—å —Å –ø—Ä–æ—Å—Ç—ã–º–∏ –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ML –º–æ–¥–µ–ª–µ–π.
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Optional, Tuple
from sklearn.dummy import DummyRegressor, DummyClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import logging

class BaselineModels:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    def create_regression_baselines(self, X_train: np.ndarray, y_train: np.ndarray, 
                                  X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Dict[str, float]]:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
        
        Args:
            X_train, y_train: –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_test, y_test: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        """
        baselines = {}
        
        # 1. Dummy Regressor (—Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
        dummy_mean = DummyRegressor(strategy='mean')
        dummy_mean.fit(X_train, y_train)
        y_pred_mean = dummy_mean.predict(X_test)
        
        baselines['dummy_mean'] = {
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_mean)),
            'mae': mean_absolute_error(y_test, y_pred_mean),
            'r2': r2_score(y_test, y_pred_mean)
        }
        
        # 2. Dummy Regressor (–º–µ–¥–∏–∞–Ω–∞)
        dummy_median = DummyRegressor(strategy='median')
        dummy_median.fit(X_train, y_train)
        y_pred_median = dummy_median.predict(X_test)
        
        baselines['dummy_median'] = {
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_median)),
            'mae': mean_absolute_error(y_test, y_pred_median),
            'r2': r2_score(y_test, y_pred_median)
        }
        
        # 3. Linear Regression
        try:
            lr = LinearRegression()
            lr.fit(X_train, y_train)
            y_pred_lr = lr.predict(X_test)
            
            baselines['linear_regression'] = {
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lr)),
                'mae': mean_absolute_error(y_test, y_pred_lr),
                'r2': r2_score(y_test, y_pred_lr)
            }
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –≤ Linear Regression: {e}")
            baselines['linear_regression'] = {'rmse': float('inf'), 'mae': float('inf'), 'r2': -float('inf')}
        
        # 4. Random Forest (–ø—Ä–æ—Å—Ç–æ–π)
        try:
            rf = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)
            rf.fit(X_train, y_train)
            y_pred_rf = rf.predict(X_test)
            
            baselines['random_forest_simple'] = {
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf)),
                'mae': mean_absolute_error(y_test, y_pred_rf),
                'r2': r2_score(y_test, y_pred_rf)
            }
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –≤ Random Forest: {e}")
            baselines['random_forest_simple'] = {'rmse': float('inf'), 'mae': float('inf'), 'r2': -float('inf')}
        
        # 5. Persistence Model (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ = –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
        if len(y_test) > 1:
            y_pred_persist = np.roll(y_test, 1)
            y_pred_persist[0] = y_train[-1] if len(y_train) > 0 else 0
            
            baselines['persistence'] = {
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_persist)),
                'mae': mean_absolute_error(y_test, y_pred_persist),
                'r2': r2_score(y_test, y_pred_persist)
            }
        
        return baselines
    
    def create_classification_baselines(self, X_train: np.ndarray, y_train: np.ndarray, 
                                      X_test: np.ndarray, y_test: np.ndarray) -> Dict[str, Dict[str, float]]:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        
        Args:
            X_train, y_train: –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_test, y_test: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        """
        baselines = {}
        
        # 1. Dummy Classifier (most frequent)
        dummy_freq = DummyClassifier(strategy='most_frequent', random_state=42)
        dummy_freq.fit(X_train, y_train)
        y_pred_freq = dummy_freq.predict(X_test)
        
        baselines['dummy_most_frequent'] = {
            'accuracy': accuracy_score(y_test, y_pred_freq),
            'f1': f1_score(y_test, y_pred_freq, average='weighted'),
            'precision': precision_score(y_test, y_pred_freq, average='weighted'),
            'recall': recall_score(y_test, y_pred_freq, average='weighted')
        }
        
        # 2. Dummy Classifier (stratified)
        dummy_strat = DummyClassifier(strategy='stratified', random_state=42)
        dummy_strat.fit(X_train, y_train)
        y_pred_strat = dummy_strat.predict(X_test)
        
        baselines['dummy_stratified'] = {
            'accuracy': accuracy_score(y_test, y_pred_strat),
            'f1': f1_score(y_test, y_pred_strat, average='weighted'),
            'precision': precision_score(y_test, y_pred_strat, average='weighted'),
            'recall': recall_score(y_test, y_pred_strat, average='weighted')
        }
        
        # 3. Logistic Regression
        try:
            lr = LogisticRegression(random_state=42, max_iter=1000)
            lr.fit(X_train, y_train)
            y_pred_lr = lr.predict(X_test)
            
            baselines['logistic_regression'] = {
                'accuracy': accuracy_score(y_test, y_pred_lr),
                'f1': f1_score(y_test, y_pred_lr, average='weighted'),
                'precision': precision_score(y_test, y_pred_lr, average='weighted'),
                'recall': recall_score(y_test, y_pred_lr, average='weighted')
            }
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –≤ Logistic Regression: {e}")
            baselines['logistic_regression'] = {'accuracy': 0, 'f1': 0, 'precision': 0, 'recall': 0}
        
        # 4. Random Forest (–ø—Ä–æ—Å—Ç–æ–π)
        try:
            rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)
            rf.fit(X_train, y_train)
            y_pred_rf = rf.predict(X_test)
            
            baselines['random_forest_simple'] = {
                'accuracy': accuracy_score(y_test, y_pred_rf),
                'f1': f1_score(y_test, y_pred_rf, average='weighted'),
                'precision': precision_score(y_test, y_pred_rf, average='weighted'),
                'recall': recall_score(y_test, y_pred_rf, average='weighted')
            }
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –≤ Random Forest: {e}")
            baselines['random_forest_simple'] = {'accuracy': 0, 'f1': 0, 'precision': 0, 'recall': 0}
        
        return baselines
    
    def get_best_baseline(self, baselines: Dict[str, Dict[str, float]], 
                         task_type: str = 'regression') -> Tuple[str, Dict[str, float]]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à—É—é –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
        
        Args:
            baselines: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏ ('regression' –∏–ª–∏ 'classification')
            
        Returns:
            (best_model_name, best_metrics)
        """
        if not baselines:
            return None, {}
        
        if task_type == 'regression':
            # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏—â–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º R¬≤
            best_model = max(baselines.items(), key=lambda x: x[1].get('r2', -float('inf')))
        else:
            # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—â–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–µ–π accuracy
            best_model = max(baselines.items(), key=lambda x: x[1].get('accuracy', 0))
        
        return best_model
    
    def compare_with_baseline(self, model_metrics: Dict[str, float], 
                            baseline_metrics: Dict[str, float], 
                            task_type: str = 'regression') -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
        
        Args:
            model_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
            baseline_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        comparison = {
            'model_metrics': model_metrics,
            'baseline_metrics': baseline_metrics,
            'improvements': {},
            'is_better_than_baseline': True
        }
        
        if task_type == 'regression':
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º RMSE, MAE, R¬≤
            for metric in ['rmse', 'mae']:
                model_val = model_metrics.get(metric, float('inf'))
                baseline_val = baseline_metrics.get(metric, float('inf'))
                
                if baseline_val > 0 and model_val != float('inf'):
                    improvement = ((baseline_val - model_val) / baseline_val) * 100
                    comparison['improvements'][f'{metric}_improvement'] = improvement
                    comparison['improvements'][f'{metric}_better'] = model_val < baseline_val
                else:
                    comparison['improvements'][f'{metric}_improvement'] = 0
                    comparison['improvements'][f'{metric}_better'] = False
            
            # R¬≤ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
            model_r2 = model_metrics.get('r2', -float('inf'))
            baseline_r2 = baseline_metrics.get('r2', -float('inf'))
            
            if baseline_r2 != -float('inf') and model_r2 != -float('inf'):
                improvement = ((model_r2 - baseline_r2) / abs(baseline_r2)) * 100 if baseline_r2 != 0 else 0
                comparison['improvements']['r2_improvement'] = improvement
                comparison['improvements']['r2_better'] = model_r2 > baseline_r2
            else:
                comparison['improvements']['r2_improvement'] = 0
                comparison['improvements']['r2_better'] = False
            
            # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
            better_metrics = sum([
                comparison['improvements']['rmse_better'],
                comparison['improvements']['mae_better'],
                comparison['improvements']['r2_better']
            ])
            comparison['is_better_than_baseline'] = better_metrics >= 2
            
        else:  # classification
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º accuracy, f1, precision, recall
            for metric in ['accuracy', 'f1', 'precision', 'recall']:
                model_val = model_metrics.get(metric, 0)
                baseline_val = baseline_metrics.get(metric, 0)
                
                if baseline_val > 0:
                    improvement = ((model_val - baseline_val) / baseline_val) * 100
                    comparison['improvements'][f'{metric}_improvement'] = improvement
                    comparison['improvements'][f'{metric}_better'] = model_val > baseline_val
                else:
                    comparison['improvements'][f'{metric}_improvement'] = 0
                    comparison['improvements'][f'{metric}_better'] = False
            
            # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
            better_metrics = sum([
                comparison['improvements']['accuracy_better'],
                comparison['improvements']['f1_better']
            ])
            comparison['is_better_than_baseline'] = better_metrics >= 1
        
        return comparison
    
    def create_baseline_report(self, X_train: np.ndarray, y_train: np.ndarray, 
                             X_test: np.ndarray, y_test: np.ndarray,
                             task_type: str = 'regression') -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –±–∞–∑–æ–≤—ã–º –º–æ–¥–µ–ª—è–º
        
        Args:
            X_train, y_train: –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_test, y_test: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏
            
        Returns:
            –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        """
        if task_type == 'regression':
            baselines = self.create_regression_baselines(X_train, y_train, X_test, y_test)
        else:
            baselines = self.create_classification_baselines(X_train, y_train, X_test, y_test)
        
        best_baseline_name, best_baseline_metrics = self.get_best_baseline(baselines, task_type)
        
        report = {
            'task_type': task_type,
            'all_baselines': baselines,
            'best_baseline': {
                'name': best_baseline_name,
                'metrics': best_baseline_metrics
            },
            'data_info': {
                'train_samples': len(X_train),
                'test_samples': len(X_test),
                'features': X_train.shape[1] if len(X_train.shape) > 1 else 1
            }
        }
        
        self.logger.info(f"üìä –°–æ–∑–¥–∞–Ω –æ—Ç—á–µ—Ç –ø–æ –±–∞–∑–æ–≤—ã–º –º–æ–¥–µ–ª—è–º –¥–ª—è {task_type}")
        self.logger.info(f"üèÜ –õ—É—á—à–∞—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {best_baseline_name}")
        
        return report 